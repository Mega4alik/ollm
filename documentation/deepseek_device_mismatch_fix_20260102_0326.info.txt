Summary of Changes:
Resolved `RuntimeError: Expected all tensors to be on the same device` in `deepseek.py`. This was caused by the `MyDeepseekModel.forward` method prematurely moving the embedding layer (`embed_tokens`) to CPU immediately before the forward pass, while the input tensors (`input_ids`) were on the GPU.

Detailed Implementation Notes:
1. Updated `src/ollm/deepseek.py`:
   - Moved `self.embed_tokens.cpu()` from *before* the `super().forward(...)` call to *after* it.
   - Removed `self.embed_tokens.to(out.last_hidden_state.device)` from the end of the method.
   - This ensures that:
     a) `embed_tokens` matches the device of `input_ids` (GPU) during the forward pass execution.
     b) `embed_tokens` is correctly offloaded back to CPU after computation is complete, adhering to the library's memory optimization strategy.

Fixes & Caveats:
- Fix: The DeepSeek model can now execute its forward pass without device mismatch errors.
- Caveat: The embedding layer is explicitly moved to CPU after every forward pass. This adds a small overhead of moving weights back and forth but is necessary for the SSD offloading / VRAM saving design of the library.

Usage Instructions:
No changes to usage. Run the example script as before:
```bash
python3 scripts/example_deepseek_moe.py
```

Technical Metrics:
- Confirmed fix by ensuring `embed_tokens` is not moved to CPU until *after* it has been used by the parent class's forward method.
